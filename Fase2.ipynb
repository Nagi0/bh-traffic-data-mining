{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+MdlsXCq8npsPGharL5Rs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nagi0/bh-traffic-data-mining/blob/main/Fase2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autores: Bruno Leal Fonseca & Guilherme Namen Pimenta"
      ],
      "metadata": {
        "id": "gztz2OquZR9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini 1.5 Pro OO2 – Temperatura 0\n",
        "\n",
        "Prompt:\n",
        "\n",
        "Necessito de ajuda para fazer o trabalho abaixo, me informe como proceder em todas as etapas desde a coleta, processamento e geração do relatório final.\n",
        "\n",
        "O documento descreve um projeto de mineração de dados para analisar padrões de tráfego em Belo Horizonte usando dados de radares. Aqui está um guia passo a passo para realizar este projeto, expandindo os pontos do documento e adicionando detalhes práticos:\n",
        "\n",
        "Fase 1: Coleta e Tratamento de Dados\n",
        "\n",
        "\n",
        "\n",
        "1.   Download dos Dados: Baixe os arquivos JSON dos radares do portal de dados abertos da Prefeitura de Belo Horizonte (https://dados.pbh.gov.br/dataset/contagens-volumetricas-de-radares).\n",
        "2.   Organize os arquivos por mês e dia, como descrito no documento. Considere baixar dados de um período menor inicialmente para testes e desenvolvimento.\n",
        "3.   Escolha da Via: Selecione uma via principal de Belo Horizonte para focar a análise. Essa escolha reduz a complexidade inicial e permite resultados mais específicos.\n",
        "\n",
        "4.   Conversão para Formato Tabular: Os dados JSON precisam ser convertidos para um formato tabular (como CSV ou um banco de dados relacional) para facilitar o processamento. Use uma biblioteca Python como pandas para ler os arquivos JSON e criar um DataFrame. Em seguida, exporte o DataFrame para um arquivo CSV ou carregue-o em um banco de dados (PostgreSQL, MySQL, SQLite, etc.)."
      ],
      "metadata": {
        "id": "M_pyxnfWLApu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T5mq00n-ZeAP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZgQ9r9TKo9_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import json\n",
        "\n",
        "# Lista todos os arquivos JSON em um diretório\n",
        "json_files = glob.glob('ABRIL_2021/20210401/*.json')\n",
        "\n",
        "# Cria uma lista vazia para armazenar os dados\n",
        "data = []\n",
        "\n",
        "# Itera sobre os arquivos JSON\n",
        "for file in json_files:\n",
        "    with open(file, 'r') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                data.append(json.loads(line))\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Erro ao decodificar JSON em {file}\")\n",
        "\n",
        "# Cria um DataFrame pandas\n",
        "df = pd.DataFrame(data)\n",
        "# Seleciona as colunas relevantes\n",
        "df = df[['ID_EQP', 'DATA_HORA', 'MILESEGUNDO', 'FAIXA', 'ID_DE_ENDEREÇO', 'VELOCIDADE_DA_VIA', 'VELOCIDADE_AFERIDA', 'CLASSIFICACAO', 'TAMANHO', 'NUM_SERIE', 'LATITUDE', 'LONGITUDE', 'ENDEREÇO', 'SENTIDO']]\n",
        "\n",
        "# Salva o DataFrame em um arquivo CSV\n",
        "df.to_csv('dados_radares.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crítca**\n",
        "\n",
        "A base de dados é bem complexa e esta divida em várias arquivos zip contendo uma grande quantidade de informações, foi necessário criar um projeto a parte para reunir as informações necessárias e filtrar os dados. Mesmo filtrando por uma via, a quantidade de informações é muito grande então decidimos filtrar pelo horário de pico da manhã das 07:00 às 09:00.\n",
        "\n",
        "Uma vantagem foi a criação do código para converter de json para dataframe."
      ],
      "metadata": {
        "id": "qwoDfGdXM57M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM**\n",
        "Limpeza e Pré-processamento:\n",
        "\n",
        "1. Valores Ausentes: Trate valores ausentes (NaN) na tabela. Dependendo da quantidade, você pode remover as linhas com valores ausentes ou imputar valores (média, mediana, etc.).\n",
        "\n",
        "2. Formatação de Data/Hora: Converta a coluna DATA_HORA para o tipo datetime do pandas para facilitar a análise temporal.\n",
        "\n",
        "3. Filtragem por Via: Filtre o DataFrame para incluir apenas os dados da via selecionada."
      ],
      "metadata": {
        "id": "T-V99JiISDQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crítica**\n",
        "\n",
        "Para bases de dados simples o procedimento funciona bem. O problema é que a base de dados em questão é muito grande cerca de 12GB compactados. Sendo assim o colab não suporta o procedimento. É necessário um pequeno projeto para gerar o csv para ser processado. O geração da base é um processo bem complexo e demanda, uma análise mais completa. A recomendação da LLM é padrão e bem simples."
      ],
      "metadata": {
        "id": "Gw8eB8CvSUbe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-aM9G1pRVgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM**\n",
        "\n",
        "Fase 2: Determinar o Formato da Transação\n",
        "\n",
        "1. Discretização: Converta variáveis numéricas contínuas (como velocidade e tamanho do veículo) em categorias. Por exemplo:\n",
        "  * Velocidade: Baixa (0-40 km/h), Média (41-60 km/h), Alta (61+ km/h)\n",
        "  * Tamanho: Pequeno (moto), Médio (carro), Grande (ônibus/caminhão)\n",
        "  * Horário: Madrugada, Manhã, Tarde, Noite, etc.\n",
        "\n",
        "2. Criação de Transações: Defina o que constitui uma \"transação\" para a mineração de padrões. Algumas opções:\n",
        "\n",
        "  1. Por Registro: Cada linha da tabela é uma transação, contendo as características do veículo e o horário.\n",
        "\n",
        "  2. Por Intervalo de Tempo: Agrupe os dados em intervalos de tempo (15 minutos, 30 minutos, 1 hora) e crie transações com as características dos veículos que passaram naquele intervalo."
      ],
      "metadata": {
        "id": "MH1R8-HkTVgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crítica**\n",
        "\n",
        "A LLM não gerou o código necessário para converter as variáveis contínuas, porém gerou uma boa forma de se segmentar as variáveis contínuas, com relação à velocidade mais uma categoria, Muit Alta (100+ Km/h), seria interessante. Com relação ao horário a definição do horário de pico da manhã e tarde seriam também interessantes."
      ],
      "metadata": {
        "id": "gkmjcjfmUD2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM**\n",
        "\n",
        "Fase 3: Processamento (Mineração de Padrões)\n",
        "\n",
        "  1. Preparação dos Dados: Converta os dados para o formato exigido pelo algoritmo de mineração de padrões escolhido (Apriori, FP-Growth, Eclat, etc.). A biblioteca mlxtend em Python oferece implementações desses algoritmos.\n",
        "\n",
        "  2. Execução do Algoritmo: Execute o algoritmo escolhido com os parâmetros apropriados (suporte mínimo, confiança mínima, etc.)."
      ],
      "metadata": {
        "id": "omEQ3wwkVC7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supondo que 'df_transacoes' é o seu DataFrame de transações\n",
        "frequent_itemsets = apriori(df_transacoes, min_support=0.05, use_colnames=True)\n",
        "print(frequent_itemsets)\n"
      ],
      "metadata": {
        "id": "f0xQJwiuVZsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crítica**\n",
        "\n",
        "A bibliteca não possui a implementação do algoritmo Eclat ele não trata das descobertas de regras, medidas de utilidade e não trata e não faz uma análise dos dados de forma sequencial. As recomendações são muito vagas e não refletem uma análise e programação mais profunda. Poderiam ser informados mais opções de bibliotecas."
      ],
      "metadata": {
        "id": "4YKUyHlBVfCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM**\n",
        "\n",
        "Fase 4: Reporte\n",
        "\n",
        "1. Análise dos Resultados: Interprete os padrões frequentes encontrados. Quais combinações de características ocorrem com frequência? Existem padrões interessantes relacionados a horários, tipos de veículos e velocidade?\n",
        "\n",
        "2. Visualização: Crie gráficos e tabelas para visualizar os resultados e facilitar a compreensão.\n",
        "\n",
        "3. Relatório Final: Escreva um relatório detalhando o processo, os resultados e as conclusões. Inclua:\n",
        "\n",
        "  1. Descrição do problema e dos dados\n",
        "  2. Metodologia utilizada (pré-processamento, mineração de padrões)\n",
        "  3. Resultados e interpretação\n",
        "  4. Limitações do estudo\n",
        "  5. Sugestões para trabalhos futuros\n",
        "\n",
        "Ferramentas e Tecnologias:\n",
        "\n",
        " * Linguagem de Programação: Python\n",
        "\n",
        " * Bibliotecas Python: pandas, mlxtend, matplotlib (para visualização), seaborn (para visualização), json, glob\n",
        "\n",
        " * Banco de Dados (opcional): PostgreSQL, MySQL, SQLite\n",
        "\n",
        " * Algoritmos de Mineração de Padrões: Apriori, FP-Growth, Eclat (implementados na mlxtend)\n",
        "\n",
        " * Ambiente de Desenvolvimento: Jupyter Notebook, VS Code, PyCharm\n",
        "\n",
        "Lembre-se de documentar cada etapa do processo e justificar as escolhas feitas. Isso tornará seu trabalho mais robusto e replicável. Comece com um conjunto de dados menor para testar e refinar seu código antes de processar todo o conjunto de dados."
      ],
      "metadata": {
        "id": "FjrslwX4XPXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crítica**\n",
        "\n",
        "O processo final de análise dos resultados é bem complexo, e a LLM o resumiu de forma muito simples em forma de tópicos."
      ],
      "metadata": {
        "id": "JHzKKkOUXTe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida o seguinte prompot foi enviado: Iremos utilizar um agrupamento por tempo, como seria melhor e como deve interpretar os resultados?"
      ],
      "metadata": {
        "id": "uxv9UQgFYK7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM**\n",
        "\n",
        "Utilizar o agrupamento por tempo adiciona uma dimensão interessante à análise, permitindo identificar padrões que variam ao longo do dia. Aqui está como você pode fazer isso e interpretar os resultados:\n",
        "\n",
        "1. Definindo o Intervalo de Tempo:\n",
        "\n",
        "  Escolha um intervalo de tempo apropriado para o agrupamento. As opções comuns incluem:\n",
        "\n",
        "  * 15 minutos: Oferece granularidade fina, mas pode resultar em muitos grupos e padrões complexos.\n",
        "\n",
        "  * 30 minutos: Um bom equilíbrio entre granularidade e complexidade.\n",
        "\n",
        "  * 1 hora: Menos granular, mas mais fácil de interpretar e pode revelar padrões diários mais amplos.\n",
        "\n",
        " * Por período do dia: Manhã, tarde, noite, madrugada. Útil para identificar padrões gerais em cada período.\n",
        "\n",
        "A escolha do intervalo depende do seu objetivo de análise e da natureza dos dados. Comece com um intervalo maior (1 hora) e, se necessário, refine para intervalos menores.\n",
        "\n",
        "2. Agrupando os Dados com Pandas:\n",
        "\n",
        " * Use a função groupby() do pandas para agrupar os dados pelo intervalo de tempo escolhido. Primeiro, certifique-se de que a coluna DATA_HORA esteja no formato datetime."
      ],
      "metadata": {
        "id": "gDikOU1CYWCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Converte a coluna 'DATA_HORA' para datetime\n",
        "df['DATA_HORA'] = pd.to_datetime(df['DATA_HORA'])\n",
        "\n",
        "# Agrupa por hora\n",
        "df_agrupado = df.groupby(pd.Grouper(key='DATA_HORA', freq='H'))\n",
        "\n",
        "# Exemplo: calcular a velocidade média por hora\n",
        "velocidade_media_por_hora = df_agrupado['VELOCIDADE_AFERIDA'].mean()\n",
        "print(velocidade_media_por_hora)\n",
        "\n",
        "# Criando transações por hora com as características dos veículos\n",
        "transacoes = []\n",
        "for nome_grupo, grupo in df_agrupado:\n",
        "    transacao = []\n",
        "    for index, row in grupo.iterrows():\n",
        "        transacao.append(f\"Velocidade_{row['VELOCIDADE_AFERIDA_DISCRETIZADA']}\")  # Usando a velocidade discretizada\n",
        "        transacao.append(f\"Classificacao_{row['CLASSIFICACAO']}\")\n",
        "        # Adicione outras características relevantes\n",
        "    transacoes.append(transacao)\n",
        "\n",
        "# Agora 'transacoes' é uma lista de listas, onde cada lista interna representa uma hora e contém as características dos veículos que passaram naquela hora.\n"
      ],
      "metadata": {
        "id": "eW4fspe6YpCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crítica**\n",
        "A LLM não entedeu que iremos particionar as transações em unidades sequenciais para realizar a mineração de padrões sequencias. E não realizou a mineração de sequencias frequentes,"
      ],
      "metadata": {
        "id": "KgTNHTRcYv3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM**\n",
        "\n",
        "3. Mineração de Padrões:\n",
        "\n",
        "Aplique o algoritmo de mineração de padrões escolhido às transações geradas no passo anterior. Lembre-se de que agora cada transação representa um intervalo de tempo.\n",
        "\n",
        "4. Interpretando os Resultados:\n",
        "\n",
        "Os padrões frequentes encontrados representarão combinações de características que ocorrem com frequência em determinados intervalos de tempo. Por exemplo:\n",
        "\n",
        "\"Velocidade_Alta\" e \"Classificacao_Moto\" às 22h: Indica que motos com alta velocidade são comuns às 22h.\n",
        "\n",
        "\"Velocidade_Baixa\" e \"Classificacao_Caminhao\" das 7h às 8h: Sugere congestionamento de caminhões no horário de pico da manhã.\n",
        "\n",
        "\"Velocidade_Media\" e \"Faixa_Esquerda\" das 18h às 19h: Indica que a faixa da esquerda é usada principalmente por veículos com velocidade média durante o horário de pico da tarde.\n",
        "\n",
        "Visualização:\n",
        "\n",
        "Gráficos de Linha: Mostre a frequência de certos padrões ao longo do tempo.\n",
        "\n",
        "Heatmaps: Visualize a frequência de padrões em diferentes horários do dia e dias da semana.\n",
        "\n",
        "Considerações Adicionais:\n",
        "\n",
        "Tendências Temporais: Analise como os padrões mudam ao longo do tempo. Existem padrões sazonais? Os padrões mudam nos finais de semana?\n",
        "\n",
        "Comparação entre Vias: Compare os padrões encontrados em diferentes vias para identificar diferenças no comportamento do tráfego.\n",
        "\n",
        "Contexto Externo: Considere fatores externos que podem influenciar os padrões, como eventos, feriados, condições climáticas, etc.\n",
        "\n",
        "Ao agrupar por tempo e analisar os padrões frequentes, você poderá obter insights valiosos sobre o comportamento do tráfego em diferentes horários e identificar áreas que precisam de atenção especial em termos de segurança e fluxo de veículos. Lembre-se de documentar suas descobertas e conclusões de forma clara e concisa."
      ],
      "metadata": {
        "id": "5MzzkURSZFtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Crítica**\n",
        "\n",
        "A LLM recomendou análises interessantes como padrões sazonais, eventos, feriados, condições climáticas, etc. O que enriqueceria muito o trabalho. Porém ela foi vaga e muito centrada em tópicos."
      ],
      "metadata": {
        "id": "FBk-lRWbZgSo"
      }
    }
  ]
}